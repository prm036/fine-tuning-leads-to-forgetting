# üß†üîí DontForgetAboutSafety ‚úñÔ∏è‚ûó
[![Hugging Face Collection](https://img.shields.io/badge/Hugging%20Face-Collection-FFD21E?logo=huggingface&logoColor=black)](https://hf.co/collections/cwoodhayes/dontforgetaboutsafety)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.13%2B-3776AB?logo=python&logoColor=white)](https://www.python.org/downloads/)

Fine-tuning LLM's to improve word problem performance without losing prior alignment on AI safety.
Fine-tuned using [GSM8K](https://huggingface.co/datasets/openai/gsm8k), evaluated using [AILuminate](https://mlcommons.org/benchmarks/ailuminate/).

HuggingFace Model Collection: https://hf.co/collections/cwoodhayes/dontforgetaboutsafety

## üèÉ‚Äç‚ôÇÔ∏è Run Instructions
Run the following to reproduce the results shown in the paper:
```bash
./reproduce.sh
```

**Authors**: Andnet DeBoer, Conor Hayes, Praneeth Reddy Mallupalli, Robert Zhu (equal contribution)
