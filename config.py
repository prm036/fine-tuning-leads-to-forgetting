# ─── Training Configs ───────────────────────────────────────────
TRAINING_CONFIGS = [
    # Run 1 – Qwen2.5-7B baseline
    dict(
        version          = "v1",
        sft_model_name   = "Qwen/Qwen2.5-7B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 0.1,
        num_train_epochs = 2,
        train_and_shot   = 5,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.01,
    ),
    # Run 2 – Qwen2.5-7B, no few shots, higher LR, no warmup/WD
    dict(
        version          = "v2",
        sft_model_name   = "Qwen/Qwen2.5-7B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 0.1,
        num_train_epochs = 1,
        train_and_shot   = 0,
        learning_rate    = 3e-4,
        warmup_steps     = 0,
        weight_decay     = 0.0,
    ),
    # Run 3 – Qwen2.5-7B, higher weight decay
    dict(
        version          = "v3",
        sft_model_name   = "Qwen/Qwen2.5-7B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 0.1,
        num_train_epochs = 1,
        train_and_shot   = 5,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.1,
    ),
    # Run 4 – Qwen2.5-1.5B, more epochs + shots
    dict(
        version          = "v4",
        sft_model_name   = "Qwen/Qwen2.5-1.5B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 0.1,
        num_train_epochs = 3,
        train_and_shot   = 8,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.1,
    ),
    # Run 5 – Qwen2.5-1.5B, no few shots
    dict(
        version          = "v5",
        sft_model_name   = "Qwen/Qwen2.5-1.5B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 0.1,
        num_train_epochs = 2,
        train_and_shot   = 0,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.1,
    ),
    # Run 6 – Qwen2.5-1.5B, standard config
    dict(
        version          = "v6",
        sft_model_name   = "Qwen/Qwen2.5-1.5B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 0.1,
        num_train_epochs = 2,
        train_and_shot   = 5,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.01,
    ),
    # Run 7 – Qwen2.5-1.5B, lower rank/alpha (5/10)
    dict(
        version          = "v7",
        sft_model_name   = "Qwen/Qwen2.5-1.5B-Instruct",
        lora_rank        = 5,
        lora_alpha       = 10,
        lora_dropout     = 0.1,
        num_train_epochs = 2,
        train_and_shot   = 5,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.01,
    ),
    # Run 8 – Qwen2.5-1.5B, higher rank/alpha (16/32)
    dict(
        version          = "v8",
        sft_model_name   = "Qwen/Qwen2.5-1.5B-Instruct",
        lora_rank        = 16,
        lora_alpha       = 32,
        lora_dropout     = 0.1,
        num_train_epochs = 2,
        train_and_shot   = 5,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.01,
    ),
    # Run 9 – Qwen2.5-1.5B, high dropout (1.0)
    dict(
        version          = "v9",
        sft_model_name   = "Qwen/Qwen2.5-1.5B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 1.0,
        num_train_epochs = 2,
        train_and_shot   = 5,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.01,
    ),
    # Run 10 – Qwen2.5-1.5B, many epochs (10)
    dict(
        version          = "v10",
        sft_model_name   = "Qwen/Qwen2.5-1.5B-Instruct",
        lora_rank        = 8,
        lora_alpha       = 16,
        lora_dropout     = 0.1,
        num_train_epochs = 10,
        train_and_shot   = 5,
        learning_rate    = 3e-5,
        warmup_steps     = 0.05,
        weight_decay     = 0.01,
    ),
]